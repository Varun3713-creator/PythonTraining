{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268d4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194a6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('joins').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2b4fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://A315-41:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>joins</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x256698aac50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89371b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=[('I1', \"Alice\", \"HR\"),('I2', \"Bob\", \"Engineering\"),('I3', \"Charlie\", \"Marketing\"),('I4', \"David\", \"Engineering\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e60fd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+\n",
      "|emp_id|   name| department|\n",
      "+------+-------+-----------+\n",
      "|    I1|  Alice|         HR|\n",
      "|    I2|    Bob|Engineering|\n",
      "|    I3|Charlie|  Marketing|\n",
      "|    I4|  David|Engineering|\n",
      "+------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col1 = [\"emp_id\", \"name\", \"department\"]\n",
    "\n",
    "df1 = spark.createDataFrame(d1, col1)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7955e8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9abfbbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|emp_id|salary|\n",
      "+------+------+\n",
      "|    I1|1000.0|\n",
      "|    I2|1500.0|\n",
      "|    I3|1200.0|\n",
      "|    I5|1800.0|\n",
      "+------+------+\n",
      "\n",
      "root\n",
      " |-- emp_id: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = [('I1', 1000.0),('I2', 1500.0),('I3', 1200.0),('I5', 1800.0)]\n",
    "\n",
    "col2 = [\"emp_id\", \"salary\"]\n",
    "\n",
    "df2 = spark.createDataFrame(data2, col2)\n",
    "df2.show()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b17e5e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+------+\n",
      "|emp_id|   name| department|salary|\n",
      "+------+-------+-----------+------+\n",
      "|    I1|  Alice|         HR|1000.0|\n",
      "|    I2|    Bob|Engineering|1500.0|\n",
      "|    I3|Charlie|  Marketing|1200.0|\n",
      "+------+-------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inner join\n",
    "df1.join(df2,on='emp_id',how='inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9addc0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+------+\n",
      "|emp_id|   name| department|salary|\n",
      "+------+-------+-----------+------+\n",
      "|    I1|  Alice|         HR|1000.0|\n",
      "|    I2|    Bob|Engineering|1500.0|\n",
      "|    I3|Charlie|  Marketing|1200.0|\n",
      "|    I4|  David|Engineering|  NULL|\n",
      "+------+-------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#left join\n",
    "df1.join(df2,on='emp_id',how='left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db612a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+------+------+\n",
      "|emp_id|   name| department|emp_id|salary|\n",
      "+------+-------+-----------+------+------+\n",
      "|    I1|  Alice|         HR|    I1|1000.0|\n",
      "|    I2|    Bob|Engineering|    I2|1500.0|\n",
      "|    I3|Charlie|  Marketing|    I3|1200.0|\n",
      "|  NULL|   NULL|       NULL|    I5|1800.0|\n",
      "+------+-------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#right join and condition when column names are different\n",
    "df1.join(df2,df1.emp_id==df2.emp_id,how='right').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb9477c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+------+------+\n",
      "|emp_id|   name| department|emp_id|salary|\n",
      "+------+-------+-----------+------+------+\n",
      "|    I1|  Alice|         HR|    I1|1000.0|\n",
      "|    I1|  Alice|         HR|    I2|1500.0|\n",
      "|    I1|  Alice|         HR|    I3|1200.0|\n",
      "|    I1|  Alice|         HR|    I5|1800.0|\n",
      "|    I2|    Bob|Engineering|    I1|1000.0|\n",
      "|    I2|    Bob|Engineering|    I2|1500.0|\n",
      "|    I2|    Bob|Engineering|    I3|1200.0|\n",
      "|    I2|    Bob|Engineering|    I5|1800.0|\n",
      "|    I3|Charlie|  Marketing|    I1|1000.0|\n",
      "|    I3|Charlie|  Marketing|    I2|1500.0|\n",
      "|    I3|Charlie|  Marketing|    I3|1200.0|\n",
      "|    I3|Charlie|  Marketing|    I5|1800.0|\n",
      "|    I4|  David|Engineering|    I1|1000.0|\n",
      "|    I4|  David|Engineering|    I2|1500.0|\n",
      "|    I4|  David|Engineering|    I3|1200.0|\n",
      "|    I4|  David|Engineering|    I5|1800.0|\n",
      "+------+-------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c33abba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+------+\n",
      "|emp_id|   name| department|salary|\n",
      "+------+-------+-----------+------+\n",
      "|    I1|  Alice|         HR|1000.0|\n",
      "|    I2|    Bob|Engineering|1500.0|\n",
      "|    I3|Charlie|  Marketing|1200.0|\n",
      "|    I4|  David|Engineering|  NULL|\n",
      "|    I5|   NULL|       NULL|1800.0|\n",
      "+------+-------+-----------+------+\n",
      "\n",
      "+------+-------+-----------+------+\n",
      "|emp_id|   name| department|salary|\n",
      "+------+-------+-----------+------+\n",
      "|    I1|  Alice|         HR|1000.0|\n",
      "|    I2|    Bob|Engineering|1500.0|\n",
      "|    I3|Charlie|  Marketing|1200.0|\n",
      "|    I4|  David|Engineering|  NULL|\n",
      "|    I5|   NULL|       NULL|1800.0|\n",
      "+------+-------+-----------+------+\n",
      "\n",
      "+------+-------+-----------+------+\n",
      "|emp_id|   name| department|salary|\n",
      "+------+-------+-----------+------+\n",
      "|    I1|  Alice|         HR|1000.0|\n",
      "|    I2|    Bob|Engineering|1500.0|\n",
      "|    I3|Charlie|  Marketing|1200.0|\n",
      "|    I4|  David|Engineering|  NULL|\n",
      "|    I5|   NULL|       NULL|1800.0|\n",
      "+------+-------+-----------+------+\n",
      "\n",
      "+------+-------+-----------+------+\n",
      "|emp_id|   name| department|salary|\n",
      "+------+-------+-----------+------+\n",
      "|    I1|  Alice|         HR|1000.0|\n",
      "|    I2|    Bob|Engineering|1500.0|\n",
      "|    I3|Charlie|  Marketing|1200.0|\n",
      "|    I4|  David|Engineering|  NULL|\n",
      "|    I5|   NULL|       NULL|1800.0|\n",
      "+------+-------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#full/outer join\n",
    "df1.join(df2,on='emp_id',how='outer').show()\n",
    "df1.join(df2,on='emp_id',how='fullouter').show()\n",
    "df1.join(df2,on='emp_id',how='full_outer').show()\n",
    "df1.join(df2,on='emp_id',how='full').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ae2d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+\n",
      "|emp_id|   name| department|\n",
      "+------+-------+-----------+\n",
      "|    I1|  Alice|         HR|\n",
      "|    I2|    Bob|Engineering|\n",
      "|    I3|Charlie|  Marketing|\n",
      "+------+-------+-----------+\n",
      "\n",
      "+------+-------+-----------+\n",
      "|emp_id|   name| department|\n",
      "+------+-------+-----------+\n",
      "|    I1|  Alice|         HR|\n",
      "|    I2|    Bob|Engineering|\n",
      "|    I3|Charlie|  Marketing|\n",
      "+------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#leftsemi\n",
    "df1.join(df2,on='emp_id',how='leftsemi').show()\n",
    "df1.join(df2,on='emp_id',how='semi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46ba8b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------+\n",
      "|emp_id| name| department|\n",
      "+------+-----+-----------+\n",
      "|    I4|David|Engineering|\n",
      "+------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#leftanti\n",
    "df1.join(df2,on='emp_id',how='leftanti').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21ebfc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------+\n",
      "|empid|   Name|manag_id|\n",
      "+-----+-------+--------+\n",
      "|    1|   Ravi|       0|\n",
      "|    2| Tharun|       1|\n",
      "|    3|Sudheer|       1|\n",
      "|    4|  David|       2|\n",
      "+-----+-------+--------+\n",
      "\n",
      "+--------+-------+\n",
      "|employee|manager|\n",
      "+--------+-------+\n",
      "|  Tharun|   Ravi|\n",
      "| Sudheer|   Ravi|\n",
      "|   David| Tharun|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#retrieving employee name along with their manager\n",
    "from pyspark.sql.functions import col\n",
    "d=[(1, \"Ravi\", 0), (2, \"Tharun\", 1),(3, \"Sudheer\", 1),(4, \"David\", 2)]\n",
    "colm=['empid','Name','manag_id']\n",
    "df=spark.createDataFrame(d,colm)\n",
    "df.show()\n",
    "emp=df.alias('emp')\n",
    "manag=df.alias('manag')\n",
    "emp.join(manag,col('emp.manag_id')==col('manag.empid'),'inner')\\\n",
    ".select(col('emp.Name').alias('employee'),col('manag.Name').alias('manager')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19a48f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method join in module pyspark.sql.dataframe:\n",
      "\n",
      "join(other: 'DataFrame', on: Union[str, List[str], pyspark.sql.column.Column, List[pyspark.sql.column.Column], NoneType] = None, how: Optional[str] = None) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Joins with another :class:`DataFrame`, using the given join expression.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : :class:`DataFrame`\n",
      "        Right side of the join\n",
      "    on : str, list or :class:`Column`, optional\n",
      "        a string for the join column name, a list of column names,\n",
      "        a join expression (Column), or a list of Columns.\n",
      "        If `on` is a string or a list of strings indicating the name of the join column(s),\n",
      "        the column(s) must exist on both sides, and this performs an equi-join.\n",
      "    how : str, optional\n",
      "        default ``inner``. Must be one of: ``inner``, ``cross``, ``outer``,\n",
      "        ``full``, ``fullouter``, ``full_outer``, ``left``, ``leftouter``, ``left_outer``,\n",
      "        ``right``, ``rightouter``, ``right_outer``, ``semi``, ``leftsemi``, ``left_semi``,\n",
      "        ``anti``, ``leftanti`` and ``left_anti``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`DataFrame`\n",
      "        Joined DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    The following performs a full outer join between ``df1`` and ``df2``.\n",
      "    \n",
      "    >>> from pyspark.sql import Row\n",
      "    >>> from pyspark.sql.functions import desc\n",
      "    >>> df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")]).toDF(\"age\", \"name\")\n",
      "    >>> df2 = spark.createDataFrame([Row(height=80, name=\"Tom\"), Row(height=85, name=\"Bob\")])\n",
      "    >>> df3 = spark.createDataFrame([Row(age=2, name=\"Alice\"), Row(age=5, name=\"Bob\")])\n",
      "    >>> df4 = spark.createDataFrame([\n",
      "    ...     Row(age=10, height=80, name=\"Alice\"),\n",
      "    ...     Row(age=5, height=None, name=\"Bob\"),\n",
      "    ...     Row(age=None, height=None, name=\"Tom\"),\n",
      "    ...     Row(age=None, height=None, name=None),\n",
      "    ... ])\n",
      "    \n",
      "    Inner join on columns (default)\n",
      "    \n",
      "    >>> df.join(df2, 'name').select(df.name, df2.height).show()\n",
      "    +----+------+\n",
      "    |name|height|\n",
      "    +----+------+\n",
      "    | Bob|    85|\n",
      "    +----+------+\n",
      "    >>> df.join(df4, ['name', 'age']).select(df.name, df.age).show()\n",
      "    +----+---+\n",
      "    |name|age|\n",
      "    +----+---+\n",
      "    | Bob|  5|\n",
      "    +----+---+\n",
      "    \n",
      "    Outer join for both DataFrames on the 'name' column.\n",
      "    \n",
      "    >>> df.join(df2, df.name == df2.name, 'outer').select(\n",
      "    ...     df.name, df2.height).sort(desc(\"name\")).show()\n",
      "    +-----+------+\n",
      "    | name|height|\n",
      "    +-----+------+\n",
      "    |  Bob|    85|\n",
      "    |Alice|  NULL|\n",
      "    | NULL|    80|\n",
      "    +-----+------+\n",
      "    >>> df.join(df2, 'name', 'outer').select('name', 'height').sort(desc(\"name\")).show()\n",
      "    +-----+------+\n",
      "    | name|height|\n",
      "    +-----+------+\n",
      "    |  Tom|    80|\n",
      "    |  Bob|    85|\n",
      "    |Alice|  NULL|\n",
      "    +-----+------+\n",
      "    \n",
      "    Outer join for both DataFrams with multiple columns.\n",
      "    \n",
      "    >>> df.join(\n",
      "    ...     df3,\n",
      "    ...     [df.name == df3.name, df.age == df3.age],\n",
      "    ...     'outer'\n",
      "    ... ).select(df.name, df3.age).show()\n",
      "    +-----+---+\n",
      "    | name|age|\n",
      "    +-----+---+\n",
      "    |Alice|  2|\n",
      "    |  Bob|  5|\n",
      "    +-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df1.join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8296b",
   "metadata": {},
   "source": [
    "Pivot & Unpivot Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff023dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-----------+\n",
      "|emp_id|   Name|Gender| Department|\n",
      "+------+-------+------+-----------+\n",
      "|    I1|   Arul|Female|         HR|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "|    I3|Charlie|  Male|  Marketing|\n",
      "|    I6|   dwen|Female|         IT|\n",
      "|    I4|  della|  Male|Engineering|\n",
      "|    I5|  Drona|  Male|         HR|\n",
      "|    I7|  Jenny|Female|Engineering|\n",
      "|    I2| Dharma|  Male|         IT|\n",
      "+------+-------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[('I1', \"Arul\",\"Female\",\"HR\"),('I2', \"Boby\",\"Male\", \"Engineering\"),('I3', \"Charlie\",\"Male\",\"Marketing\"),('I6', \"dwen\",\"Female\", \"IT\"),\n",
    "      ('I4', \"della\",\"Male\", \"Engineering\"),('I5', \"Drona\",\"Male\", \"HR\"),('I7', \"Jenny\",\"Female\", \"Engineering\"),('I2', \"Dharma\",\"Male\", \"IT\")]\n",
    "col1 = [\"emp_id\", \"Name\",\"Gender\", \"Department\"]\n",
    "\n",
    "df_p = spark.createDataFrame(data, col1)\n",
    "df_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b2e8155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-----+\n",
      "| Department|Gender|count|\n",
      "+-----------+------+-----+\n",
      "|Engineering|  Male|    2|\n",
      "|         HR|Female|    1|\n",
      "|         IT|Female|    1|\n",
      "|  Marketing|  Male|    1|\n",
      "|         HR|  Male|    1|\n",
      "|Engineering|Female|    1|\n",
      "|         IT|  Male|    1|\n",
      "+-----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df_p.groupBy('Department','Gender').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a75a278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+\n",
      "| Department|Female|Male|\n",
      "+-----------+------+----+\n",
      "|Engineering|     1|   2|\n",
      "|         HR|     1|   1|\n",
      "|  Marketing|  NULL|   1|\n",
      "|         IT|     1|   1|\n",
      "+-----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_up=df_p.groupBy('Department').pivot('Gender').count()\n",
    "df_up.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82ac0a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---+---+---------+\n",
      "|Gender|Engineering| HR| IT|Marketing|\n",
      "+------+-----------+---+---+---------+\n",
      "|Female|          1|  1|  1|     NULL|\n",
      "|  Male|          2|  1|  1|        1|\n",
      "+------+-----------+---+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_p.groupBy('Gender').pivot('Department').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace6474",
   "metadata": {},
   "source": [
    "#unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60875507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+\n",
      "| Department|Female|Male|\n",
      "+-----------+------+----+\n",
      "|Engineering|     1|   2|\n",
      "|         HR|     1|   1|\n",
      "|  Marketing|  NULL|   1|\n",
      "|         IT|     1|   1|\n",
      "+-----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_up.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "589595ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-----+\n",
      "| Department|Gender|count|\n",
      "+-----------+------+-----+\n",
      "|Engineering|Female|    1|\n",
      "|Engineering|  Male|    2|\n",
      "|         HR|Female|    1|\n",
      "|         HR|  Male|    1|\n",
      "|  Marketing|Female| NULL|\n",
      "|  Marketing|  Male|    1|\n",
      "|         IT|Female|    1|\n",
      "|         IT|  Male|    1|\n",
      "+-----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_up.select('Department',F.expr(\"stack(2,'Female',female,'Male',male) as (Gender,count)\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1ef8c",
   "metadata": {},
   "source": [
    "#union functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5ee0a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-----------+\n",
      "|emp_id|   Name|Gender| Department|\n",
      "+------+-------+------+-----------+\n",
      "|    I1|   Arul|Female|         HR|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "|    I3|Charlie|  Male|  Marketing|\n",
      "|    I6|   dwen|Female|         IT|\n",
      "|    I4|  della|  Male|Engineering|\n",
      "+------+-------+------+-----------+\n",
      "\n",
      "+------+-----+------+-----------+\n",
      "|emp_id| Name|Gender| Department|\n",
      "+------+-----+------+-----------+\n",
      "|    I5|Drona|  Male|         HR|\n",
      "|    I7|Jenny|Female|Engineering|\n",
      "|    I2| Boby|  Male|Engineering|\n",
      "+------+-----+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[('I1', \"Arul\",\"Female\",\"HR\"),('I2', \"Boby\",\"Male\", \"Engineering\"),('I3', \"Charlie\",\"Male\",\"Marketing\"),('I6', \"dwen\",\"Female\", \"IT\"),\n",
    "      ('I4', \"della\",\"Male\", \"Engineering\")]\n",
    "data2=[('I5', \"Drona\",\"Male\", \"HR\"),('I7', \"Jenny\",\"Female\", \"Engineering\"),('I2', \"Boby\",\"Male\", \"Engineering\")]\n",
    "col1 = [\"emp_id\", \"Name\",\"Gender\", \"Department\"]\n",
    "\n",
    "df_1 = spark.createDataFrame(data, col1)\n",
    "df_2 = spark.createDataFrame(data2, col1)\n",
    "df_1.show()\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e6bd87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-----------+\n",
      "|emp_id|   Name|Gender| Department|\n",
      "+------+-------+------+-----------+\n",
      "|    I1|   Arul|Female|         HR|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "|    I3|Charlie|  Male|  Marketing|\n",
      "|    I6|   dwen|Female|         IT|\n",
      "|    I4|  della|  Male|Engineering|\n",
      "|    I5|  Drona|  Male|         HR|\n",
      "|    I7|  Jenny|Female|Engineering|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "+------+-------+------+-----------+\n",
      "\n",
      "+------+-------+------+-----------+\n",
      "|emp_id|   Name|Gender| Department|\n",
      "+------+-------+------+-----------+\n",
      "|    I1|   Arul|Female|         HR|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "|    I3|Charlie|  Male|  Marketing|\n",
      "|    I6|   dwen|Female|         IT|\n",
      "|    I4|  della|  Male|Engineering|\n",
      "|    I5|  Drona|  Male|         HR|\n",
      "|    I7|  Jenny|Female|Engineering|\n",
      "+------+-------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using union to combine two df\n",
    "df_1.union(df_2).show()\n",
    "df_1.union(df_2).drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b55531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-----------+\n",
      "|emp_id|   Name|Gender| Department|\n",
      "+------+-------+------+-----------+\n",
      "|    I1|   Arul|Female|         HR|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "|    I3|Charlie|  Male|  Marketing|\n",
      "|    I6|   dwen|Female|         IT|\n",
      "|    I4|  della|  Male|Engineering|\n",
      "|    I5|  Drona|  Male|         HR|\n",
      "|    I7|  Jenny|Female|Engineering|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "+------+-------+------+-----------+\n",
      "\n",
      "+------+-------+------+-----------+\n",
      "|emp_id|   Name|Gender| Department|\n",
      "+------+-------+------+-----------+\n",
      "|    I1|   Arul|Female|         HR|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "|    I3|Charlie|  Male|  Marketing|\n",
      "|    I6|   dwen|Female|         IT|\n",
      "|    I4|  della|  Male|Engineering|\n",
      "|    I5|  Drona|  Male|         HR|\n",
      "|    I7|  Jenny|Female|Engineering|\n",
      "+------+-------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using unionAll to combine two df\n",
    "df_1.unionAll(df_2).show()\n",
    "df_1.unionAll(df_2).distinct().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418fac40",
   "metadata": {},
   "source": [
    "unionByName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c7b888e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-----------+\n",
      "|emp_id|   Name|Gender| Department|\n",
      "+------+-------+------+-----------+\n",
      "|    I1|   Arul|Female|         HR|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "|    I3|Charlie|  Male|  Marketing|\n",
      "|    I6|   dwen|Female|         IT|\n",
      "|    I4|  della|  Male|Engineering|\n",
      "|    I5|  Drona|  Male|         HR|\n",
      "|    I7|  Jenny|Female|Engineering|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "+------+-------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_1.unionByName(df_2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c33c98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=spark.createDataFrame([(1, \"Aarav\", \"Male\"),(2, \"Ishita\", \"Female\"),(3, \"Aditya\", \"Male\")],[\"emp_id\", \"name\", \"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8709b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.printSchema()\n",
    "df_3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "feda5c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-----------+\n",
      "|emp_id|   Name|Gender| Department|\n",
      "+------+-------+------+-----------+\n",
      "|    I1|   Arul|Female|         HR|\n",
      "|    I2|   Boby|  Male|Engineering|\n",
      "|    I3|Charlie|  Male|  Marketing|\n",
      "|    I6|   dwen|Female|         IT|\n",
      "|    I4|  della|  Male|Engineering|\n",
      "|     1|  Aarav|  Male|       NULL|\n",
      "|     2| Ishita|Female|       NULL|\n",
      "|     3| Aditya|  Male|       NULL|\n",
      "+------+-------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.unionByName(df_3,allowMissingColumns=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d65cbb",
   "metadata": {},
   "source": [
    "Combining Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bdb7425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|concat(emp_id, Department)|\n",
      "+--------------------------+\n",
      "|                      I1HR|\n",
      "|             I2Engineering|\n",
      "|               I3Marketing|\n",
      "|                      I6IT|\n",
      "|             I4Engineering|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.select(F.concat(df_1['emp_id'],df_1['Department'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e193241",
   "metadata": {},
   "source": [
    "Activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3de24615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-------+------+\n",
      "|DepartmentID|EmployeeID|   Name|Salary|\n",
      "+------------+----------+-------+------+\n",
      "|         101|         1|  Alice| 80000|\n",
      "|         102|         2|    Bob| 75000|\n",
      "|         101|         3|Charlie| 90000|\n",
      "|         103|         4|  David| 60000|\n",
      "|        NULL|         5|    Eve| 70000|\n",
      "+------------+----------+-------+------+\n",
      "\n",
      "+------------+--------------+\n",
      "|DepartmentID|DepartmentName|\n",
      "+------------+--------------+\n",
      "|         101|            HR|\n",
      "|         102|            IT|\n",
      "|         103|       Finance|\n",
      "+------------+--------------+\n",
      "\n",
      "+----------+---------+---------------+\n",
      "|EmployeeID|ProjectID|    ProjectName|\n",
      "+----------+---------+---------------+\n",
      "|         1|       P1|    Recruitment|\n",
      "|         2|       P2|Website Upgrade|\n",
      "|         4|       P3|Budget Analysis|\n",
      "|      NULL|       P4| Internal Audit|\n",
      "+----------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read JSON file\n",
    "d1 = spark.read.option(\"multiLine\", \"true\").format(\"json\").load(\"C:/Users/acer/projects/employees.json\")\n",
    "d1.show()\n",
    "d2 = spark.read.option(\"multiLine\", \"true\").format(\"json\").load(\"C:/Users/acer/projects/department.json\")\n",
    "d2.show()\n",
    "d3 = spark.read.option(\"multiLine\", \"true\").format(\"json\").load(\"C:/Users/acer/projects/projects.json\")\n",
    "d3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "caecdb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-------+------+--------------+\n",
      "|DepartmentID|EmployeeID|   Name|Salary|DepartmentName|\n",
      "+------------+----------+-------+------+--------------+\n",
      "|         101|         1|  Alice| 80000|            HR|\n",
      "|         102|         2|    Bob| 75000|            IT|\n",
      "|         101|         3|Charlie| 90000|            HR|\n",
      "|         103|         4|  David| 60000|       Finance|\n",
      "|        NULL|         5|    Eve| 70000|          NULL|\n",
      "+------------+----------+-------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#retrieve all employees with their department names(also those who do not have a department)\n",
    "emp_dep=d1.join(d2,on='DepartmentID',how='left')\n",
    "emp_dep.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9ad6112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+-----+\n",
      "| null|Finance|    HR|   IT|\n",
      "+-----+-------+------+-----+\n",
      "|70000|  60000|170000|75000|\n",
      "+-----+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#total salary spent per department.\n",
    "emp_dep.groupBy().pivot(\"DepartmentName\").sum(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1f039fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|   Name|DepartmentName|\n",
      "+-------+--------------+\n",
      "|  Alice|            HR|\n",
      "|    Bob|            IT|\n",
      "|Charlie|            HR|\n",
      "|  David|       Finance|\n",
      "|    Eve|          NULL|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#All department names and their respective employee names.\n",
    "emp_dep.select('Name','DepartmentName').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "11529b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|    ProjectName| Name|\n",
      "+---------------+-----+\n",
      "|    Recruitment|Alice|\n",
      "|Website Upgrade|  Bob|\n",
      "|Budget Analysis|David|\n",
      "| Internal Audit| NULL|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#project names and the names of employees working on them.\n",
    "proj_emp=d3.join(d1,on='EmployeeID',how='left')\n",
    "proj_emp.select('ProjectName','Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5244de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emp=d1.groupBy('DepartmentID').count()\n",
    "num_proj=proj_emp.groupBy('DepartmentID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e04e54d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+---------+--------+\n",
      "|DepartmentID|DepartmentName|employees|projects|\n",
      "+------------+--------------+---------+--------+\n",
      "|         101|            HR|        2|       1|\n",
      "|         102|            IT|        1|       1|\n",
      "|         103|       Finance|        1|       1|\n",
      "+------------+--------------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#total number of employees and the total number of projects ,each department is handling\n",
    "d2.join(num_emp,on='DepartmentID',how='left').withColumnRenamed('count','employees').join(num_proj,on='DepartmentID',how='left').withColumnRenamed('count','projects').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ded7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
